"""
ì œë¯¸ë‚˜ì´ API í´ë¼ì´ì–¸íŠ¸
"""
import os
import json
import google.generativeai as genai
from src.config import get_secret

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

class GeminiClient:
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(GeminiClient, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        # ì´ë¯¸ ì´ˆê¸°í™”ëœ ê²½ìš° ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€
        if GeminiClient._initialized:
            return
            
        # Streamlit Cloudì—ì„œëŠ” st.secrets ì‚¬ìš©, ë¡œì»¬ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
        api_key = None
        
        # 1ìˆœìœ„: st.secrets ì§ì ‘ ì ‘ê·¼
        try:
            import streamlit as st
            api_key = st.secrets["GEMINI_API_KEY"]
            print(f"ğŸ” [DEBUG] GeminiClient: st.secrets ì§ì ‘ ì ‘ê·¼ ì„±ê³µ")
        except Exception as e:
            print(f"ğŸ” [DEBUG] GeminiClient: st.secrets ì§ì ‘ ì ‘ê·¼ ì‹¤íŒ¨: {e}")
            pass
        
        # 2ìˆœìœ„: st.secrets.get() ë°©ì‹
        if not api_key:
            try:
                import streamlit as st
                api_key = st.secrets.get("GEMINI_API_KEY")
                print(f"ğŸ” [DEBUG] GeminiClient: st.secrets.get() ì„±ê³µ")
            except Exception as e:
                print(f"ğŸ” [DEBUG] GeminiClient: st.secrets.get() ì‹¤íŒ¨: {e}")
                pass
        
        # 3ìˆœìœ„: get_secret ë°©ì‹
        if not api_key:
            api_key = get_secret("GEMINI_API_KEY")
            print(f"ğŸ” [DEBUG] GeminiClient: get_secret ì„±ê³µ")
        
        # 4ìˆœìœ„: í™˜ê²½ë³€ìˆ˜ fallback
        if not api_key:
            api_key = os.getenv("GEMINI_API_KEY")
            print(f"ğŸ” [DEBUG] GeminiClient: í™˜ê²½ë³€ìˆ˜ ì ‘ê·¼")
        
        if not api_key:
            print("ğŸ” [DEBUG] GeminiClient: ëª¨ë“  API í‚¤ ì ‘ê·¼ ë°©ë²• ì‹¤íŒ¨")
            raise RuntimeError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        print(f"ğŸ” [DEBUG] GeminiClient: API í‚¤ íšë“ ì„±ê³µ, ê¸¸ì´={len(api_key)}")
        
        genai.configure(api_key=api_key)
        
        # ì œë¯¸ë‚˜ì´ ëª¨ë¸ ì„¤ì •
        # ì„¸ì…˜ ìƒíƒœì—ì„œ ëª¨ë¸ ì„ íƒ, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        import streamlit as st
        model_name = st.session_state.get("selected_gemini_model") or get_secret("GEMINI_MODEL") or os.getenv("GEMINI_MODEL", "gemini-2.5-pro")
        
        # ì„¸ì…˜ ìƒíƒœì—ì„œ temperature ì„ íƒ, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        temperature = st.session_state.get("gemini_temperature", 0.3)
        
        generation_config = genai.types.GenerationConfig(
            temperature=temperature
        )
        
        # ThinkingConfig ì„¤ì • (gemini-2.5-proì—ì„œ ì§€ì›, ë²„ì „ì— ë”°ë¼ ì„ íƒì  ì‚¬ìš©)
        thinking_config = None
        try:
            if hasattr(genai.types, 'ThinkingConfig'):
                thinking_config = genai.types.ThinkingConfig(
                    thinking_budget=-1,  # ë¬´ì œí•œ ì‚¬ê³  ì˜ˆì‚°
                )
                print(f"ğŸ” [DEBUG] ThinkingConfig ì‚¬ìš© ê°€ëŠ¥")
            else:
                print(f"ğŸ” [DEBUG] ThinkingConfig ì‚¬ìš© ë¶ˆê°€ëŠ¥ (ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë¬¸ì œ)")
        except Exception as e:
            print(f"ğŸ” [DEBUG] ThinkingConfig ìƒì„± ì‹¤íŒ¨: {e}")
            thinking_config = None
        
        try:
            if thinking_config:
                self.model = genai.GenerativeModel(
                    model_name,
                    generation_config=generation_config,
                    thinking_config=thinking_config
                )
                print(f"âœ… ì œë¯¸ë‚˜ì´ ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ (ThinkingConfig í¬í•¨): {model_name}")
            else:
                self.model = genai.GenerativeModel(
                    model_name,
                    generation_config=generation_config
                )
                print(f"âœ… ì œë¯¸ë‚˜ì´ ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ (ThinkingConfig ì œì™¸): {model_name}")
        except Exception as e:
            print(f"âŒ ëª¨ë¸ {model_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì¶œë ¥
            try:
                available_models = self.list_available_models()
                print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡: {available_models}")
            except:
                print("ğŸ“‹ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨")
            
            # ëŒ€ì²´ ëª¨ë¸ ì‹œë„
            fallback_models = ["gemini-1.5-flash", "gemini-1.5-flash-latest", "gemini-pro"]
            for fallback_model in fallback_models:
                try:
                    print(f"ğŸ”„ ëŒ€ì²´ ëª¨ë¸ ì‹œë„: {fallback_model}")
                    self.model = genai.GenerativeModel(
                        fallback_model,
                        generation_config=generation_config,
                        thinking_config=thinking_config
                    )
                    print(f"âœ… ëŒ€ì²´ ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ: {fallback_model}")
                    break
                except Exception as fallback_error:
                    print(f"âŒ ëŒ€ì²´ ëª¨ë¸ {fallback_model} ì‹¤íŒ¨: {fallback_error}")
                    continue
            else:
                raise RuntimeError(f"ëª¨ë“  ì œë¯¸ë‚˜ì´ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {e}")
        
        # ì´ˆê¸°í™” ì™„ë£Œ í‘œì‹œ
        GeminiClient._initialized = True

    def review_content(self, system_prompt: str, user_prompt: str) -> str:
        """ë‚´ìš© ê²€í† ë¥¼ ìœ„í•œ ì œë¯¸ë‚˜ì´ API í˜¸ì¶œ"""
        try:
            # ì œë¯¸ë‚˜ì´ì—ì„œëŠ” system instructionì„ ì§€ì›í•˜ë¯€ë¡œ ì´ë¥¼ í™œìš©
            # system_promptë¥¼ system instructionìœ¼ë¡œ, user_promptë¥¼ user messageë¡œ ë¶„ë¦¬
            response = self.model.generate_content(
                user_prompt,
                system_instruction=system_prompt
            )
            
            # ì‘ë‹µ ë””ë²„ê¹… ì •ë³´ ì¶œë ¥ (ë¬¸ì œ ë°ì´í„° ì¶œë ¥ ë°©ì§€ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬)
            # print(f"DEBUG: ì œë¯¸ë‚˜ì´ ì‘ë‹µ íƒ€ì…: {type(response)}")
            # print(f"DEBUG: ì‘ë‹µ ì†ì„±ë“¤: {dir(response)}")
            
            # ì‘ë‹µì˜ ëª¨ë“  ì •ë³´ í™•ì¸
            # if hasattr(response, 'text'):
            #     print(f"DEBUG: response.text ê¸¸ì´: {len(response.text) if response.text else 0}")
            # if hasattr(response, 'candidates'):
            #     print(f"DEBUG: candidates ê°œìˆ˜: {len(response.candidates) if response.candidates else 0}")
            #     if response.candidates:
            #         candidate = response.candidates[0]
            #         print(f"DEBUG: ì²« ë²ˆì§¸ candidate ì†ì„±ë“¤: {dir(candidate)}")
            #         if hasattr(candidate, 'content'):
            #             print(f"DEBUG: candidate.content íƒ€ì…: {type(candidate.content)}")
            #             if hasattr(candidate.content, 'parts'):
            #                 print(f"DEBUG: parts ê°œìˆ˜: {len(candidate.content.parts) if candidate.content.parts else 0}")
            
            # ê¸°ë³¸ì ìœ¼ë¡œ text ë°˜í™˜
            if response.text:
                return response.text
            else:
                # textê°€ ì—†ëŠ” ê²½ìš° candidatesì—ì„œ ì¶”ì¶œ ì‹œë„
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        text_parts = []
                        for part in candidate.content.parts:
                            if hasattr(part, 'text') and part.text:
                                text_parts.append(part.text)
                        if text_parts:
                            return '\n'.join(text_parts)
                
                return "âŒ ì œë¯¸ë‚˜ì´ ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
        except Exception as e:
            raise RuntimeError(f"ì œë¯¸ë‚˜ì´ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")

    def list_available_models(self) -> list:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì œë¯¸ë‚˜ì´ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            models = genai.list_models()
            available_models = []
            for model in models:
                if 'generateContent' in model.supported_generation_methods:
                    available_models.append(model.name.replace('models/', ''))
            return available_models
        except Exception as e:
            print(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def is_available(self) -> bool:
        """ì œë¯¸ë‚˜ì´ API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            # ì§ì ‘ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            api_key = os.getenv("GEMINI_API_KEY")
            # print(f"DEBUG is_available: Direct os.getenv('GEMINI_API_KEY'): {bool(api_key)}")
            
            if not api_key:
                # get_secretë„ ì‹œë„
                api_key = get_secret("GEMINI_API_KEY")
                # print(f"DEBUG is_available: get_secret('GEMINI_API_KEY'): {bool(api_key)}")
            
            if api_key:
                # print(f"DEBUG is_available: API key length: {len(api_key)}")
                pass
            
            return bool(api_key)
        except Exception as e:
            # print(f"DEBUG is_available: Error checking GEMINI_API_KEY: {e}")
            return False
