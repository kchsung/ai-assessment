"""
ì œë¯¸ë‚˜ì´ API í´ë¼ì´ì–¸íŠ¸
"""
import os
import json
from datetime import datetime
import google.generativeai as genai
from src.config import get_secret

# ë¬¸ì œ êµì •ìš© ìƒˆë¡œìš´ íŒ¨í‚¤ì§€ (google-genai)
try:
    from google import genai as new_genai
    from google.genai import types
    NEW_GENAI_AVAILABLE = True
    _CORRECT_PROBLEM_AVAILABLE = True
    # ë””ë²„ê¹…: íŒ¨í‚¤ì§€ ë²„ì „ í™•ì¸
    try:
        import google.genai
        _GENAI_VERSION = getattr(google.genai, '__version__', 'unknown')
    except:
        _GENAI_VERSION = 'unknown'
except ImportError as e:
    NEW_GENAI_AVAILABLE = False
    new_genai = None
    types = None
    _CORRECT_PROBLEM_AVAILABLE = False
    _GENAI_VERSION = None
    _IMPORT_ERROR = str(e)

# .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

class GeminiClient:
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super(GeminiClient, cls).__new__(cls)
        return cls._instance
    
    def __init__(self):
        # ì´ë¯¸ ì´ˆê¸°í™”ëœ ê²½ìš° ì¤‘ë³µ ì´ˆê¸°í™” ë°©ì§€
        if GeminiClient._initialized:
            return
            
        # Streamlit Cloudì—ì„œëŠ” st.secrets ì‚¬ìš©, ë¡œì»¬ì—ì„œëŠ” í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©
        api_key = None
        
        # 1ìˆœìœ„: st.secrets ì§ì ‘ ì ‘ê·¼
        try:
            import streamlit as st
            api_key = st.secrets["GEMINI_API_KEY"]
        except Exception:
            pass
        
        # 2ìˆœìœ„: st.secrets.get() ë°©ì‹
        if not api_key:
            try:
                import streamlit as st
                api_key = st.secrets.get("GEMINI_API_KEY")
            except Exception:
                pass
        
        # 3ìˆœìœ„: get_secret ë°©ì‹
        if not api_key:
            api_key = get_secret("GEMINI_API_KEY")
        
        # 4ìˆœìœ„: í™˜ê²½ë³€ìˆ˜ fallback
        if not api_key:
            api_key = os.getenv("GEMINI_API_KEY")
        
        if not api_key:
            raise RuntimeError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        genai.configure(api_key=api_key)
        
        # ì œë¯¸ë‚˜ì´ ëª¨ë¸ ì„¤ì •
        # ì„¸ì…˜ ìƒíƒœì—ì„œ ëª¨ë¸ ì„ íƒ, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        import streamlit as st
        model_name = st.session_state.get("selected_gemini_model") or get_secret("GEMINI_MODEL") or os.getenv("GEMINI_MODEL", "gemini-2.5-pro")
        
        # ì„¸ì…˜ ìƒíƒœì—ì„œ temperature ì„ íƒ, ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        temperature = st.session_state.get("gemini_temperature", 0.3)
        
        generation_config = genai.types.GenerationConfig(
            temperature=temperature
        )
        
        # ThinkingConfig ì„¤ì • (gemini-2.5-proì—ì„œ ì§€ì›, ë²„ì „ì— ë”°ë¼ ì„ íƒì  ì‚¬ìš©)
        thinking_config = None
        try:
            if hasattr(genai.types, 'ThinkingConfig'):
                thinking_config = genai.types.ThinkingConfig(
                    thinking_budget=-1,  # ë¬´ì œí•œ ì‚¬ê³  ì˜ˆì‚°
                )
        except Exception:
            thinking_config = None
        
        try:
            if thinking_config:
                self.model = genai.GenerativeModel(
                    model_name,
                    generation_config=generation_config,
                    thinking_config=thinking_config
                )
            else:
                self.model = genai.GenerativeModel(
                    model_name,
                    generation_config=generation_config
                )
        except Exception as e:
            # ëŒ€ì²´ ëª¨ë¸ ì‹œë„
            fallback_models = ["gemini-1.5-flash", "gemini-1.5-flash-latest", "gemini-pro"]
            for fallback_model in fallback_models:
                try:
                    self.model = genai.GenerativeModel(
                        fallback_model,
                        generation_config=generation_config,
                        thinking_config=thinking_config
                    )
                    break
                except Exception:
                    continue
            else:
                raise RuntimeError(f"ëª¨ë“  ì œë¯¸ë‚˜ì´ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {e}")
        
        # ì´ˆê¸°í™” ì™„ë£Œ í‘œì‹œ
        GeminiClient._initialized = True

    def review_content(self, system_prompt: str, user_prompt: str) -> str:
        """ë‚´ìš© ê²€í† ë¥¼ ìœ„í•œ ì œë¯¸ë‚˜ì´ API í˜¸ì¶œ"""
        try:
            # ë””ë²„ê¹… ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            import streamlit as st
            if hasattr(st, 'session_state'):
                if "gemini_api_debug" not in st.session_state:
                    st.session_state.gemini_api_debug = []
                
                from datetime import datetime
                # ëª¨ë¸ ì´ë¦„ ì¶”ì¶œ
                model_name = "unknown"
                if hasattr(self, 'model') and self.model:
                    if hasattr(self.model, 'model_name'):
                        model_name = self.model.model_name
                    elif hasattr(self.model, 'name'):
                        model_name = self.model.name
                    elif isinstance(self.model, str):
                        model_name = self.model
                
                api_debug_info = {
                    "timestamp": datetime.now().isoformat(),
                    "method": "review_content",
                    "model": model_name,
                    "parameters": {
                        "temperature": "ê¸°ë³¸ê°’ (ë¯¸ì„¤ì •)",
                        "thinking_level": "ë¯¸ì§€ì›",
                        "media_resolution": "ë¯¸ì§€ì›",
                        "response_mime_type": "text/plain (ê¸°ë³¸ê°’)",
                        "response_schema": "ë¯¸ì§€ì› (ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ)"
                    },
                    "prompts": {
                        "system_prompt": system_prompt,
                        "system_prompt_length": len(system_prompt),
                        "user_prompt": user_prompt,
                        "user_prompt_length": len(user_prompt),
                        "combined_prompt": f"{system_prompt}\n\n{user_prompt}",
                        "combined_prompt_length": len(system_prompt) + len(user_prompt) + 2
                    }
                }
                st.session_state.gemini_api_debug.append(api_debug_info)
            
            # ìµœì‹  Google Generative AI ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œëŠ” contents ë°°ì—´ì„ ì‚¬ìš©
            contents = [
                {"role": "user", "parts": [{"text": f"{system_prompt}\n\n{user_prompt}"}]}
            ]
            response = self.model.generate_content(contents)
            
            
            # ê¸°ë³¸ì ìœ¼ë¡œ text ë°˜í™˜
            if response.text:
                return response.text
            else:
                # textê°€ ì—†ëŠ” ê²½ìš° candidatesì—ì„œ ì¶”ì¶œ ì‹œë„
                if hasattr(response, 'candidates') and response.candidates:
                    candidate = response.candidates[0]
                    if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                        text_parts = []
                        for part in candidate.content.parts:
                            if hasattr(part, 'text') and part.text:
                                text_parts.append(part.text)
                        if text_parts:
                            return '\n'.join(text_parts)
                
                return "âŒ ì œë¯¸ë‚˜ì´ ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
        except Exception as e:
            raise RuntimeError(f"ì œë¯¸ë‚˜ì´ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")

    def list_available_models(self) -> list:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì œë¯¸ë‚˜ì´ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ"""
        try:
            models = genai.list_models()
            available_models = []
            for model in models:
                if 'generateContent' in model.supported_generation_methods:
                    available_models.append(model.name.replace('models/', ''))
            return available_models
        except Exception:
            return []

    def is_available(self) -> bool:
        """ì œë¯¸ë‚˜ì´ API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            # ì§ì ‘ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°
            api_key = os.getenv("GEMINI_API_KEY")
            
            if not api_key:
                # get_secretë„ ì‹œë„
                api_key = get_secret("GEMINI_API_KEY")
            
            return bool(api_key)
        except Exception:
            return False
    
    def correct_problem(self, system_prompt: str, user_prompt: str) -> str:
        """
        ë¬¸ì œ êµì •ì„ ìœ„í•œ ì œë¯¸ë‚˜ì´ API í˜¸ì¶œ (ìƒˆë¡œìš´ google-genai íŒ¨í‚¤ì§€ ì‚¬ìš©)
        
        Args:
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            user_prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (ë¬¸ì œ JSON í¬í•¨)
            
        Returns:
            str: êµì •ëœ ë¬¸ì œì˜ JSON ë¬¸ìì—´
            
        Raises:
            RuntimeError: google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ê±°ë‚˜ API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ
        """
        if not NEW_GENAI_AVAILABLE:
            raise RuntimeError("google-genai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-genaië¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        try:
            # API í‚¤ ê°€ì ¸ì˜¤ê¸°
            api_key = None
            
            # 1ìˆœìœ„: st.secrets ì§ì ‘ ì ‘ê·¼
            try:
                import streamlit as st
                api_key = st.secrets["GEMINI_API_KEY"]
            except Exception:
                pass
            
            # 2ìˆœìœ„: st.secrets.get() ë°©ì‹
            if not api_key:
                try:
                    import streamlit as st
                    api_key = st.secrets.get("GEMINI_API_KEY")
                except Exception:
                    pass
            
            # 3ìˆœìœ„: get_secret ë°©ì‹
            if not api_key:
                api_key = get_secret("GEMINI_API_KEY")
            
            # 4ìˆœìœ„: í™˜ê²½ë³€ìˆ˜ fallback
            if not api_key:
                api_key = os.getenv("GEMINI_API_KEY")
            
            if not api_key:
                raise RuntimeError("GEMINI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            
            # ìƒˆë¡œìš´ í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            client = new_genai.Client(api_key=api_key)
            
            # ëª¨ë¸ ì„¤ì •
            model = "gemini-3-pro-preview"
            
            # Contents êµ¬ì„± (ì°¸ì¡° ì½”ë“œì™€ ë™ì¼í•˜ê²Œ user roleë§Œ ì‚¬ìš©)
            contents = [
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_text(text=user_prompt),
                    ],
                ),
            ]
            
            # System instruction êµ¬ì„± (GenerateContentConfigì— í¬í•¨)
            system_instruction = [
                types.Part.from_text(text=system_prompt),
            ]
            
            # JSON ìŠ¤í‚¤ë§ˆ ì •ì˜ (ì‚¬ìš©ì ì œê³µ ìŠ¤í‚¤ë§ˆ êµ¬ì¡° ì‚¬ìš©)
            response_schema = types.Schema(
                type=types.Type.OBJECT,
                required=["meta_layer", "user_view_layer", "system_view_layer", "evaluation_layer"],
                properties={
                    "meta_layer": types.Schema(
                        type=types.Type.OBJECT,
                        required=["id", "lang", "category", "difficulty", "time_limit", "problem_type", "target_template_code", "active"],
                        properties={
                            "idx": types.Schema(
                                type=types.Type.INTEGER,
                            ),
                            "id": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "lang": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "category": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "topic": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "difficulty": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "time_limit": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "problem_type": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "target_template_code": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "created_by": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "created_at": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "updated_at": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "active": types.Schema(
                                type=types.Type.BOOLEAN,
                            ),
                        },
                    ),
                    "user_view_layer": types.Schema(
                        type=types.Type.OBJECT,
                        required=["title", "summary", "scenario", "task"],
                        properties={
                            "title": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "summary": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "topic_summary": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "scenario": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "scenario_public": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "task": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "task_instruction": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "goal": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "requirements": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "constraints": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "constraints_public": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "opening_line": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "first_question": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "starter_guide": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "attachments": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "task_raw": types.Schema(
                                type=types.Type.STRING,
                            ),
                        },
                    ),
                    "system_view_layer": types.Schema(
                        type=types.Type.OBJECT,
                        required=["data_facts", "guide"],
                        properties={
                            "data_facts": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.OBJECT,
                                    required=["key", "value"],
                                    properties={
                                        "key": types.Schema(
                                            type=types.Type.STRING,
                                        ),
                                        "value": types.Schema(
                                            type=types.Type.STRING,
                                        ),
                                    },
                                ),
                            ),
                            "hidden_constraints": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "reveal_rules": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "guide": types.Schema(
                                type=types.Type.OBJECT,
                                required=["tools", "approach", "considerations"],
                                properties={
                                    "tools": types.Schema(
                                        type=types.Type.ARRAY,
                                        items=types.Schema(
                                            type=types.Type.STRING,
                                        ),
                                    ),
                                    "approach": types.Schema(
                                        type=types.Type.ARRAY,
                                        items=types.Schema(
                                            type=types.Type.STRING,
                                        ),
                                    ),
                                    "considerations": types.Schema(
                                        type=types.Type.ARRAY,
                                        items=types.Schema(
                                            type=types.Type.STRING,
                                        ),
                                    ),
                                },
                            ),
                            "reference": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.OBJECT,
                                    required=["key", "value"],
                                    properties={
                                        "key": types.Schema(
                                            type=types.Type.STRING,
                                        ),
                                        "value": types.Schema(
                                            type=types.Type.STRING,
                                        ),
                                    },
                                ),
                            ),
                        },
                    ),
                    "evaluation_layer": types.Schema(
                        type=types.Type.OBJECT,
                        required=["evaluation", "process_criteria", "result_criteria", "scoring_weights", "critical_fail_rules"],
                        properties={
                            "evaluation": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "process_criteria": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "result_criteria": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                            "scoring_weights": types.Schema(
                                type=types.Type.OBJECT,
                                required=["process", "result"],
                                properties={
                                    "process": types.Schema(
                                        type=types.Type.NUMBER,
                                    ),
                                    "result": types.Schema(
                                        type=types.Type.NUMBER,
                                    ),
                                },
                            ),
                            "model_answer": types.Schema(
                                type=types.Type.STRING,
                            ),
                            "critical_fail_rules": types.Schema(
                                type=types.Type.ARRAY,
                                items=types.Schema(
                                    type=types.Type.STRING,
                                ),
                            ),
                        },
                    ),
                },
            )
            
            # GenerateContentConfig ì„¤ì • (ì°¸ì¡° ì½”ë“œì™€ ë™ì¼í•˜ê²Œ)
            temperature = 1.3
            thinking_level = "HIGH"
            media_resolution = "MEDIA_RESOLUTION_HIGH"
            response_mime_type = "application/json"
            
            # GenerateContentConfigì— system_instruction í¬í•¨ (ì°¸ì¡° ì½”ë“œì™€ ë™ì¼)
            generate_content_config = types.GenerateContentConfig(
                temperature=temperature,
                thinking_config=types.ThinkingConfig(
                    thinking_level=thinking_level,
                ),
                media_resolution=media_resolution,
                response_mime_type=response_mime_type,
                response_schema=response_schema,
                system_instruction=system_instruction,
            )
            
            # ë””ë²„ê¹… ì •ë³´ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥
            import streamlit as st
            if hasattr(st, 'session_state'):
                if "gemini_api_debug" not in st.session_state:
                    st.session_state.gemini_api_debug = []
                
                from datetime import datetime
                api_debug_info = {
                    "timestamp": datetime.now().isoformat(),
                    "method": "correct_problem",
                    "model": model,
                    "parameters": {
                        "temperature": temperature,
                        "thinking_level": thinking_level,
                        "media_resolution": media_resolution,
                        "response_mime_type": response_mime_type,
                        "response_schema": "ì„¤ì •ë¨ (4ê°œ ë ˆì´ì–´: meta_layer, user_view_layer, system_view_layer, evaluation_layer)"
                    },
                    "prompts": {
                        "system_prompt": system_prompt,
                        "system_prompt_length": len(system_prompt),
                        "user_prompt": user_prompt,
                        "user_prompt_length": len(user_prompt)
                    }
                }
                st.session_state.gemini_api_debug.append(api_debug_info)
            
            # ë””ë²„ê¹…: ì„¤ì • í™•ì¸
            if hasattr(st, 'write'):
                with st.expander("ğŸ” Gemini API í˜¸ì¶œ ì„¤ì •", expanded=False):
                    st.write(f"**ëª¨ë¸**: {model}")
                    st.write(f"**Temperature**: {temperature}")
                    st.write(f"**Thinking Level**: {thinking_level}")
                    st.write(f"**Response MIME Type**: {response_mime_type}")
                    st.write(f"**System Instruction ê¸¸ì´**: {len(system_prompt)} ë¬¸ì")
                    st.write(f"**User Prompt ê¸¸ì´**: {len(user_prompt)} ë¬¸ì")
                    st.write(f"**Response Schema**: ì„¤ì •ë¨ (4ê°œ ë ˆì´ì–´)")
            
            # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µ ë°›ê¸°
            response_text = ""
            chunk_count = 0
            for chunk in client.models.generate_content_stream(
                model=model,
                contents=contents,
                config=generate_content_config,
            ):
                if hasattr(chunk, 'text') and chunk.text:
                    response_text += chunk.text
                    chunk_count += 1
            
            # ë””ë²„ê¹…: ì‘ë‹µ í™•ì¸
            if hasattr(st, 'write'):
                with st.expander("ğŸ“¥ Gemini API ì‘ë‹µ ì •ë³´", expanded=False):
                    st.write(f"**ì‘ë‹µ ê¸¸ì´**: {len(response_text)} ë¬¸ì")
                    st.write(f"**Chunk ê°œìˆ˜**: {chunk_count}")
                    st.write(f"**ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì)**:")
                    st.code(response_text[:500] if response_text else "ì‘ë‹µ ì—†ìŒ")
            
            return response_text
            
        except Exception as e:
            raise RuntimeError(f"ë¬¸ì œ êµì • API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
